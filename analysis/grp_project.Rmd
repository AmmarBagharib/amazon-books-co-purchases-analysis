---
title: "Group Project (exploration)"
author: "group"
date: "2023-09-15"
output: html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(dplyr)
library(tidyr)
library(igraph)
library(data.table)
library(glue)
library(gridExtra)
library(ggplot2)
library(stringr)
library(here)
library(caret)
library(pROC)
library(glmnet)
```

```{r , setup, include=FALSE}
#set working directory to project root folder
knitr::opts_knit$set(root.dir = here())
```

# Project Background

Established in 1995 as a pioneering online bookstore, Amazon has been a cherished destination for book enthusiasts for several decades. While the company has evolved and expanded into a diverse range of industries, it has consistently maintained its status as a go-to hub for book shoppers.

In the scope of this project, our objective is to delve into the evolving co-purchase patterns of books over time, understand it's characteristics and underlying patterns. With these information, we'll then develop a model that can provide personalized book recommendations based on books which the customer has added to his/her basket.

In doing so, we anticipate that our efforts will yield a mutually beneficial outcome. By facilitating book discoveries and guiding readers to titles they might not have encountered otherwise, we aim to stimulate sales on the platform, benefiting both Amazon and its thriving community of book lovers.

**1. Network Characteristics**

Note:

On our end, the metadata is collected in summer 2006 (possible dates is Wed, 21 Jun 2006 â€“ Sat, 23 Sept 2006), and our co-purchase data: `amazon0312` was collected in March 02 2003.

The number of months from the midpoint of summer, 7 August 2006, to March 02 2003 is 30 months 3 weeks, thus we round up to 31 months.

we've filtered for such book-to-book co-purchases:
1. With average reviews > 1 in 31 month period (for both books)
2. in a co-purchase, both books have a valid genre i.e., not an empty string

```{r read_data}
set.seed(123)

# Read the graph from the GraphML file
g <- read_graph(here("outputs/filtered_graph_0601.graphml"), format = "graphml")
# read filtered book data
books_df <- read.csv(here("outputs/book_filtered.csv"))
# changing id column and vertex ids from 'int' to 'chr' dtype
#books_df$id <- as.character(books_df$id)

g

head(books_df)
```

```{r appending_features_to_baseline_dataset}
baseline_df <- read.csv('../data/baseline_dataset.csv')

### I modified this code to only leftjoin "first_genre" and "num_main_genres" because the baseline_dataset.csv contains info of edgelist + books_df info already
# removed: rating, reviews, salesrank
baseline_df <- baseline_df %>%
  left_join(books_df %>%
              select(id, first_genre, cleaned_genres, num_main_genres, rating, reviews, salesrank) %>%
              rename(V1_rating = rating, V1_reviews = reviews, V1_salesrank = salesrank, V1_first_genre = first_genre, V1_genres = cleaned_genres, V1_num_main_genres = num_main_genres),
            by  = c("V1" = "id")) %>%
  left_join(books_df %>%
              select(id, first_genre, cleaned_genres, num_main_genres, rating, reviews, salesrank) %>%
              rename(V2_rating = rating, V2_reviews = reviews, V2_salesrank = salesrank, V2_first_genre = first_genre, V2_genres = cleaned_genres, V2_num_main_genres = num_main_genres),
            by  = c("V2" = "id")) %>%
  # append is_common first genre column
  mutate(is_common_main_genre = as.integer(V1_first_genre == V2_first_genre))

```


```{r downsampling_baseline_dataset}
class_proportions <- baseline_df %>% group_by(is_connected) %>% tally()
print(class_proportions)
# The dataset is highly imbalanced and this needs to be handled as if it is not dealt with properly, the algorithm will not be able to learn the characteristics of the minority class properly. Therefore, up-sampling or down-sampling techniques can be used to ensure equal or more balanced proportions between the two classes.


# Code to split into training and test data
set.seed(123)  
# This function ensures automatically that class proportions are maintained
index <- createDataPartition(baseline_df$is_connected, p = 0.7, list = FALSE)
train_data <- subset(baseline_df[index, ], select=-c(`V1_first_genre`,
                                                     `V1_genres`,
                                                     `V2_first_genre`,
                                                     `V2_genres`,
                                                     `num_common_genre`
                                                     ))

test_data <- subset(baseline_df[-index, ], select=-c(`V1_first_genre`,
                                                     `V1_genres`,
                                                     `V2_first_genre`,
                                                     `V2_genres`,
                                                     `num_common_genre`
                                                     ))

# converting dependent variable to factor as many packages require to be in factor
train_data$is_connected <- as.factor(train_data$is_connected)
test_data$is_connected <- as.factor(test_data$is_connected)

print(paste("Number of positive class in train data:", sum(train_data$is_connected == 1)))
print(paste("Number of negative class in original data:", sum(train_data$is_connected == 0)))

# downsampling of the majority class for TRAIN set only. Cannot touch TEST set.
downsampled_data <- downSample(train_data[, -which(names(train_data) == "is_connected")], train_data$is_connected)

# need to rename the "is_connected" column
colnames(downsampled_data)[colnames(downsampled_data) == "Class"] <- "is_connected"

print(paste("Number of positive class in downsampled data:", sum(downsampled_data$is_connected == 1)))
print(paste("Number of negative class in downsampled data:", sum(downsampled_data$is_connected == 0)))

head(downsampled_data)
```
```{r scaling_data}
# scaling train data
x_var_train <- downsampled_data[, !(names(downsampled_data) %in% c("is_connected", "V1", "V2"))]
scaled_x_train <- scale(x_var_train)
downsampled_data <- cbind(scaled_x_train, is_connected = downsampled_data$is_connected, V1 = downsampled_data$V1, V2 = downsampled_data$V2)

# we are only interested in the POSITIVE classes of the test data. We evaluate model based on the accuracy in predicting positive class only. We do not care about the negative class. Hence, metrics like ROC-AUC, confusion matrix etc will no longer be necessary.

test_data_positive <- test_data[test_data$is_connected==1,]
x_var_test <- test_data_positive[, !(names(test_data_positive) %in% c("is_connected", "V1", "V2"))]
scaled_x_test <- scale(x_var_test)
test_data_positive <- cbind(scaled_x_test, is_connected = test_data_positive$is_connected, V1 = test_data_positive$V1, V2 = test_data_positive$V2)
nrow(test_data_positive)

# converting back to dataframe
downsampled_data <- data.frame(downsampled_data)
test_data_positive <- data.frame(test_data_positive)

# converting the dependent variable to 0 and 1; somehow it changed to 1 and 2
downsampled_data$is_connected <- downsampled_data$is_connected - 1
test_data_positive$is_connected <- test_data_positive$is_connected - 1
downsampled_data$is_connected <- as.factor(downsampled_data$is_connected)
test_data_positive$is_connected <- as.factor(test_data_positive$is_connected)
```


```{r creating_baseline_model}
# First create a baseline model: Logistic regression. It is chosen for its simplicity and easy interpretability. Come up with a baseline model first without any feature selection or hyperparameter tuning first and see performance.

# training data for logit: Drop V1 and V2 column
baseline_logit_data <- downsampled_data %>% select(-V1, -V2)
baseline_logit_model <- glm(is_connected ~ ., data = baseline_logit_data, 
                            family = binomial(link = "logit"))

# Summary of the model
summary(baseline_logit_model)
```



```{r baseline_model_performance}
# dropping V1 and V2 for test data
baseline_logit_test_data <- test_data_positive %>% select(-V1, -V2)

# predictions
predicted_probs <- predict(baseline_logit_model, 
                           newdata = baseline_logit_test_data, type = "response")
threshold <- 0.5
predicted_classes <- ifelse(predicted_probs > threshold, 1, 0)

# accuracy
accuracy = sum(predicted_classes == 1) / nrow(test_data_positive)
# Print the accuracy
print(paste("Accuracy of baseline model", accuracy))


# # Confusion matrix
# confusion <- confusionMatrix(as.factor(predicted_classes), as.factor(test_data_positive$is_connected))
# print(confusion)
# 
# # ROC curve and AUC
# roc_obj <- roc(test_data_positive$is_connected, predicted_probs)
# auc(roc_obj)
# plot(roc_obj, main="ROC curve", col="blue", lwd=2)

```


```{r node_attributes}

# store attributes into a data.frame
node_attributes_df=data.frame(vertex_id=V(g)$name, 
                              degree = degree(g),
                              closeness=closeness(g, mode='all'),
                              betweenness=betweenness(g, directed=FALSE),
                              transitivity=transitivity(g, type = "local"), # There are many NaN transitivity values; it means these nodes are isolated? What the heck suddenly there are no more NaN values??
                              eigencentrality = eigen_centrality(g)$vector,
                              pagerank = page_rank(g)$vector,
                              component_membership = components(g)$membership) #should we specify weakly or strongly connected component?

# replacing NaN transitivity with value = 2 and treat it as a continuous variable first. Alternatively, we could also just one hot encode the transitivity column and treat it as a categorical variable
node_attributes_df$transitivity[is.na(node_attributes_df$transitivity)] <- 2

head(node_attributes_df)

# scaling the node attributes dataframe
scaled_node_attributes_df <- node_attributes_df %>% select(-vertex_id) %>% scale() %>% as.data.frame() %>% cbind(vertex_id = node_attributes_df$vertex_id)
```

```{r merging_baseline_dataset_node_attributes}
## downsampled_data vertex ids are currently in int format. Convert to chr for left_join(), then convert back to int before model training

downsampled_data_2 = downsampled_data

downsampled_data_2$V1 = as.character(downsampled_data_2$V1)
downsampled_data_2$V2 = as.character(downsampled_data_2$V2)

merged_data <- downsampled_data_2 %>% 
  left_join(scaled_node_attributes_df %>% 
              select(vertex_id, degree, closeness, betweenness, 
                     transitivity, eigencentrality, pagerank, component_membership) %>% 
              rename(V1_degree = degree, 
                     V1_closeness = closeness, 
                     V1_betweenness = betweenness,
                     V1_transitivity = transitivity, 
                     V1_eigencentrality = eigencentrality, 
                     V1_pagerank = pagerank, 
                     V1_component_membership = component_membership), 
            by = c("V1" = "vertex_id")) %>% 
  left_join(scaled_node_attributes_df %>% select(vertex_id, degree, 
                                          closeness, betweenness, 
                                          transitivity, eigencentrality,
                                          pagerank, component_membership) %>% 
              rename(V2_degree = degree, V2_closeness = closeness, 
                     V2_betweenness = betweenness, V2_transitivity = transitivity, 
                     V2_eigencentrality = eigencentrality, V2_pagerank = pagerank, 
                     V2_component_membership = component_membership), 
            by = c("V2" = "vertex_id"))


# dropping V1 and V2 from the merged data
merged_data <- merged_data %>% select(-V1, -V2)
head(merged_data)
```

```{r merged_model_training}
merged_logit_model <- glm(is_connected ~ ., 
                          data = merged_data, 
                          family = binomial(link = "logit"))

# Summary of the model
summary(merged_logit_model)
```


```{r merging_baseline_dataset_node_attributes_test_set}
# wr are only interested in the positive classes of the test data
# need to leftjoin test data set also
merged_test_data_positive <- test_data_positive
merged_test_data_positive$V1 <- as.character(merged_test_data_positive$V1)
merged_test_data_positive$V2 <- as.character(merged_test_data_positive$V2)

merged_test_data_positive <- merged_test_data_positive %>% 
  left_join(scaled_node_attributes_df %>% select(vertex_id, degree, closeness, 
                                          betweenness, transitivity, eigencentrality, 
                                          pagerank, component_membership) %>% 
              rename(V1_degree = degree, V1_closeness = closeness, 
                     V1_betweenness = betweenness, V1_transitivity = transitivity, 
                     V1_eigencentrality = eigencentrality, V1_pagerank = pagerank, 
                     V1_component_membership = component_membership), 
            by = c("V1" = "vertex_id")) %>% 
  left_join(scaled_node_attributes_df %>% select(vertex_id, degree, closeness,
                                          betweenness, transitivity, eigencentrality, 
                                          pagerank, component_membership) %>% 
              rename(V2_degree = degree, V2_closeness = closeness, 
                     V2_betweenness = betweenness, V2_transitivity = transitivity, 
                     V2_eigencentrality = eigencentrality, V2_pagerank = pagerank, 
                     V2_component_membership = component_membership), 
            by = c("V2" = "vertex_id"))

 # dropping V1 and V2 columns
merged_test_data_positive <- merged_test_data_positive %>% select(-V1, -V2)
head(merged_test_data_positive)
```


```{r merged_model_performance}
# predictions
merged_predicted_probs <- predict(merged_logit_model, 
                                  newdata = merged_test_data_positive, 
                                  type = "response")
threshold <- 0.5
merged_predicted_classes <- ifelse(merged_predicted_probs > threshold, 1, 0)

# accuracy
merged_accuracy = sum(merged_predicted_classes == 1) / nrow(merged_test_data_positive)
# Print the accuracy
print(paste("Accuracy of baseline model", merged_accuracy))

# # Confusion matrix
# merged_confusion <- confusionMatrix(as.factor(merged_predicted_classes), as.factor(merged_test_data$is_connected))
# print(merged_confusion)
# 
# # ROC curve and AUC
# merged_roc_obj <- roc(merged_test_data$is_connected, merged_predicted_probs)
# auc(merged_roc_obj)
# plot(merged_roc_obj, main="ROC curve", col="blue", lwd=2)
```

```{r LASSO_feature_selection_hyperparameter_tuning}

set.seed(42)

# shuffle the code first before CV because currently, the dataset is order in the way where it is all negative class then positive class
merged_data <- merged_data[sample(nrow(merged_data)), ]
x <- as.matrix(merged_data[, -which(names(merged_data) == "is_connected")])
y <- merged_data$is_connected

# Fit the regularized LASSO regression model
# Here, 'alpha' is set to 1 for LASSO
# use cv.glmnet to perform cross-validation to find the optimal lambda value. Default nfolds = 10.
cv_fit <- cv.glmnet(x, y, family = "binomial", alpha = 1)
plot(cv_fit)

# optimal lambda
best_lambda <- cv_fit$lambda.min
cat("Best lambda from cross-validation:", best_lambda, "\n")

# tuned model
tuned_model <- glmnet(x, y, family = "binomial", alpha = 1, lambda = best_lambda)

lasso_coefficients <- coef(tuned_model, s = best_lambda)
```

```{r tuned_model_predictions}
x_test <- as.matrix(merged_test_data_positive[, -which(names(merged_test_data_positive) == "is_connected")])
y_test <- merged_test_data_positive$is_connected

tuned_preds <- ifelse(predict(tuned_model, newx = x_test, type = "respons", s = best_lambda) > 0.5, 1, 0)

# accuracy
tuned_accuracy = sum(tuned_preds == 1) / nrow(merged_test_data_positive)
# Print the accuracy
print(paste("Accuracy of baseline model", tuned_accuracy))
```

```{r merging_node_attributes_books_df}
merged_df = books_df %>% mutate(id = as.character(id)) %>% 
  left_join(node_attributes_df, by = c("id" = "vertex_id"))
head(merged_df)
```

**2.1. Degree Centrality**

The degree distribution of our network exhibits a power-law distribution, a characteristic often seen in naturally occurring networks. Majority of books in our network have low degree centrality, typically three or fewer connections. On the far right of the distribution, we observe a small group of books with 12 or more first-degree connections, indicating a significant influence on the purchase of other books.

This suggests that most books within the network neither strongly influence the purchase of other books nor are significantly influenced by other books. Examining these high in-degree centrality outliers can provide valuable insights, which could allow us to formulate effective cross-selling strategies that enhance co-purchase tendencies.

```{r deg_visualization, fig.width=15, fig.height=5}
#function to plot histogram
plot_hist <- function(g, title, x_label, y_label, log_scale = FALSE) {
  labels <- labs(y = y_label, x = x_label, title = title)  # Added title parameter
  graph <- ggplot() + geom_histogram(aes(x = g), bins = 10) + labels
  
  if (log_scale == TRUE) {
    return(graph + ls)
  } else {
    return(graph)
  }
}

#calculate in, out and all degree centrality for each graph
deg <- degree(g)

#visualize
plot_hist(deg, "degree distribution for 0302", "degree", "frequency")
```

**2.2. Degree Centrality**
The low network density of 0.000598 in the network indicates that, relative to the total possible connections between books, there are very few actual co-purchases. This suggests that the network is quite sparse, with a limited number of co-purchases taking place.

Global transitivity measures how likely the neighbors of two connected nodes are connected to each other. In the case of our co-purchase network, it measures the likelihood that the alters of two books which are co-purchased together are also co-purchased with each other. The moderate global transitivity value of 0.242 tells us that there is a noteworthy degree of clustering or transitivity within this sparse network. 

This means that, despite the overall sparsity, there is a tendency for co-purchased books to have shared co-purchases with other books in the network. In simpler terms, when two books are co-purchased together, there is a relatively higher likelihood that other books co-purchased with those two are also co-purchased with each other. 

This suggests that there are distinct co-purchase patterns or niche markets within the network. Products within these clusters frequently co-purchase with each other, even if the overall network is not densely interconnected.

```{r graph-attributes}
global_transitivity = transitivity(g, type="global")
density = graph.density(g)
print(paste("The global transitivity of the graph is", global_transitivity, "and the graph density is", density))
```

# Clusters

```{r component, fig.width = 15, fig.height = 10}
#get largest component
comps <- clusters(g)
largest_comp_ind <- which.max(comps$csize)
largest_comp_vert <- which(comps$membership == largest_comp_ind)
largest_comp_subg <- induced_subgraph(g, largest_comp_vert)

#visualize largest component
plot(largest_comp_subg, layout = layout.fruchterman.reingold(g), vertex.size = degree(largest_comp_subg))
#degree distribution for sampled graph
plot_hist(degree(g), "Degree Centrality distribution for sampled graph", "degree centrality", "frequency", log_scale = FALSE)
#degree distribution for largest component
plot_hist(degree(largest_comp_subg), "Degree Centrality distribution for largest component", "degree centrality", "frequency", log_scale = FALSE)
```


# Clustering

Source Codes

https://cran.r-project.org/web/packages/linkprediction/linkprediction.pdf

https://rpubs.com/writetosamadalvi/CommunityDetection

https://users.dimi.uniud.it/~massimo.franceschet/R/communities.html

https://rstudio-pubs-static.s3.amazonaws.com/734940_93adb495f0e34ca291fcda1d214129d1.html#Service_as_a_Freelancer









