---
title: "Group Project (exploration)"
author: "Chen Yang"
date: "2023-09-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(dplyr)
library(tidyr)
library(igraph)
library(data.table)
library(glue)
library(gridExtra)
library(ggplot2)
library(glue)
library(stringr)
library(here)
```


```{r , setup, include=FALSE}
#set working directory to project root folder
knitr::opts_knit$set(root.dir = here())
setwd(here())
```
**Project Background**

Established in 1995 as a pioneering online bookstore, Amazon has been a cherished destination for book enthusiasts for several decades. While the company has evolved and expanded into a diverse range of industries, it has consistently maintained its status as a go-to hub for book shoppers.

In the scope of this project, our objective is to delve into the evolving co-purchase patterns of books over time, understand it's characteristics and underlying patterns. With these information, we'll then develop a model that can provide personalized book recommendations based on books which the customer has added to his/her basket.

In doing so, we anticipate that our efforts will yield a mutually beneficial outcome. By facilitating book discoveries and guiding readers to titles they might not have encountered otherwise, we aim to stimulate sales on the platform, benefiting both Amazon and its thriving community of book lovers.

**1. Preprocessing the Metadata**

```{r metadata}
#read metadata txt
meta <- readLines(paste0("../data/amazon-meta.txt"))

#exclude blanks, reviews, actor/actress info so that we deal with less data
meta <- meta[meta != "" & !grepl("^\\s*\\d+-\\d+-\\d+\\s*cutomer:\\s*[A-Za-z0-9]+", meta) & !grepl("\\|Actors & Actresses\\[\\d+\\]\\|[^|]*", meta)]

#define regex pattern and identify item id, start/stop index for each item
pattern <- "^\\s*[iI]+\\s*[dD]+\\s*:+\\s*\\d+$"
start_ind <- which(grepl(pattern, meta))
stop_ind <- c(start_ind[2:length(start_ind)]-1, length(meta))

#function to handle empty ID matches
conditional_fn <- function(x) {
  ifelse(length(x) == 0, NA, x)
}

#get item ids with regex
item_id <- meta[start_ind] %>% regmatches(., gregexpr("\\d+", .)) %>% lapply(., conditional_fn) %>% unlist()


#compile into dataframe
item_index <- data.frame(id = item_id, start = start_ind, stop = stop_ind, length = stop_ind - start_ind + 1)

#get product type
grp_pattern <- "group:\\s*(.+)"
product_type <- c()

for (i in 1:length(item_index %>% row.names())) {
  test_item <- meta[item_index$start[i]:item_index$stop[i]]
  type <- test_item %>% .[grep(grp_pattern, .)] %>% str_match(., grp_pattern) %>% .[2]
  product_type <- c(product_type, type)
}

item_index$type <- product_type

#view distribution of attribute length
item_index %>% group_by(length) %>% summarize(n = n())

#save
#write.csv(item_index, "item_index.csv", row.names = FALSE)
```


```{r extract_genre_from_books}
#create another dataframe which only contain books
item_index_books <- item_index[item_index$type == "Book",] %>% drop_na()

###Extract book genres - the data is formatted such that each book has a main genre, followed by a bunch of sub-genres. 
### Each book can belong in multiple main and sub-genres. For simplicity, we'll only be looking at the main genre as there are too many sub-genres

#define regex pattern for elements containing genre info
genre_pattern <- "\\|\\w+\\[\\d+\\]\\|"

#empty list to hold extracted genres and the re-concatenated genre string
main_genres <- c()
cleaned_genres <- c()

#elements to exclude as they are not genres
non_genre_elems<- c(
  "Books", "Subjects", "Specialty Stores", 
  "Formats", "Amazon.com Stores", "jp-unknown2", 
  "jp-unknown3","jp-unknown1", "By Publisher", 
  "O'Reilly", "Categories","John Wiley & Sons",
  "VHS", "DVD", ""
)

#iterate over every book
for (i in 1:length(row.names(item_index_books))) {
  if (i %% 1000 == 0) {
    print(glue("processed {i} entries"))
  }
  #select an item's character vector and trim white spaces on either side of each element
  char_vec <- meta[item_index_books$start[i]:item_index_books$stop[i]] %>% trimws()
  
  #extract and clean genre using regex
  genres_dirty <- char_vec[which(grepl(genre_pattern, char_vec))] %>% #select the elements which contain genre info
    paste(., collapse = "") %>% #combine them together using paste
    strsplit("\\|") %>% #split into elements using "|" as delimiter
    unlist() %>% #unlist
    str_replace_all(., "\\[\\d+\\]", "") #remove genre and sub-genre ID
  
  #remove non-genre elements from list
  genres_clean <- genres_dirty %>% unique() %>% .[!(. %in% non_genre_elems)]
  
  cleaned_genres <- c(cleaned_genres, paste(genres_clean, collapse = "|"))
  
  #add main genre to main_genres vector if it's not already inside
  main_genres <- c(main_genres, genres_clean[1][!(genres_clean[1] %in% main_genres)])
}

#remove NA elements
main_genres <- main_genres[!(is.na(main_genres))]
main_genres[!(main_genres %in% non_genre_elems)]

#check if number of cleaned genres equal to number of rows in books dataframe
item_index_books$cleaned_genres <- cleaned_genres
#save csv
#write.csv(item_index_books, "item_index_books.csv", row.names = FALSE)
```


```{r genre_one_hot_encoding}
#one-hot encoding function
OHE_genre <- function(main_genres, str) {
  op <- lapply(main_genres, function (x) {grepl(x, str)}) %>% unlist() %>% as.numeric()
  return(op)
}

#one-hot encoding for genre
encoded_data <- lapply(cleaned_genres, function(x) {OHE_genre(main_genres, x)})
encoded_data <- encoded_data %>% as.data.frame() %>% transpose()
colnames(encoded_data) <- main_genres

#bind column-wise
item_index_books <- cbind(item_index_books, encoded_data)

#save csv
#write.csv(item_index_books, "item_index_books.csv", row.names = FALSE)

#preview
#item_index_books
```


**2. Network Characteristics**

```{r read_data}
set.seed(123)

#read edge lists
ls_0302 <- read.table('../data/Amazon0302.txt')
ls_0312 <- read.table('../data/Amazon0312.txt')
ls_0505 <- read.table('../data/Amazon0505.txt')
ls_0601 <- read.table('../data/Amazon0601.txt')

#read processed metadata
book_data <- read.csv("item_index_books.csv")

#form graphs
g0302 <- graph_from_data_frame(ls_0302, directed = TRUE)
g0312 <- graph_from_data_frame(ls_0312, directed = TRUE)
g0505 <- graph_from_data_frame(ls_0505, directed = TRUE)
g0601 <- graph_from_data_frame(ls_0601, directed = TRUE)

#subset graphs to only include book nodes
graph_ls <- c("g0302", "g0312", "g0505", "g0601")

for (each in graph_ls) {
  graph <- get(each)
  glue("original node count for {each}: {length(V(graph))}") %>% print()
  
  subset <- induced_subgraph(graph, V(graph)[V(graph) %in% book_data$id])
  assign(each, subset)
  glue("subset graph node count for {each}: {length(V(subset))}") %>% print()
  cat("\n")
}


```
**2.1. Degree Centrality**

In the context of our project, in-degree represents the number of co-purchases which a given book is involved in - books with high in-degree are frequently purchased together with other books. From the graphs, we can see that the network's in-degree distribution follows the power-law, which is a characteristic of a naturally-occurring graph; most books have low in-degree and only a small number of them have high in-degree. the distribution is extremely left-skewed and we have to use a log scale to properly visualize them. To the extreme right, we can see that a small number of books are extremely popular and are co-purchased with more than 1500 other books. 

```{r deg_visualization, fig.width=15, fig.height=5}
#function to plot histogram
plot_hist <- function(g, title, x_label, y_label, log_scale = TRUE) {
  ls <- scale_y_continuous(trans = "log10")
  labels <- labs(y = y_label, x = x_label, title = title)  # Added title parameter
  graph <- ggplot() + geom_histogram(aes(x = g)) + labels
  
  if (log_scale == TRUE) {
    return(graph + ls)
  } else {
    return(graph)
  }
}

#calculate in-degree
indeg_0302 <- degree(g0302, mode = "in")
indeg_0312 <- degree(g0312, mode = "in")
indeg_0505 <- degree(g0505, mode = "in")
indeg_0601 <- degree(g0601, mode = "in")

indeg_hist0302 <- plot_hist(indeg_0302, "in-degree distribution for 0302", "in-degree", "frequency (log scale)")
indeg_hist0312 <- plot_hist(indeg_0312, "in-degree distribution for 0312", "in-degree", "frequency (log scale)")
indeg_hist0505 <- plot_hist(indeg_0505, "in-degree distribution for 0505", "in-degree", "frequency (log scale)")
indeg_hist0601 <- plot_hist(indeg_0601, "in-degree distribution for 0601", "in-degree", "frequency (log scale)")

grid.arrange(indeg_hist0302, indeg_hist0312, indeg_hist0505, indeg_hist0601, ncol = 2)
```

On the other hand, out-degree represents the number of co-purchases which a given book resulted in. Books with high out-degree are more likely to result in a high number of co-purchases. From the graphs shown below, we can see that the out-degree distribution is generally right-skewed - this means that majority of the books are likely to induce a large number of co-purchases; most commonly, 7.5 books are purchased together and in the most extreme cases, 11 books are purchased together.

```{r deg_visualization_out, fig.width = 15, fig.height = 5}
#calculate out-degree
outdeg_0302 <- degree(g0302, mode = "out")
outdeg_0312 <- degree(g0312, mode = "out")
outdeg_0505 <- degree(g0505, mode = "out")
outdeg_0601 <- degree(g0601, mode = "out")

outdeg_hist0302 <- plot_hist(outdeg_0302, "out-degree distribution for 0302", "out-degree", "frequency (log scale)", log_scale = FALSE)
outdeg_hist0312 <- plot_hist(outdeg_0312, "out-degree distribution for 0312", "out-degree", "frequency (log scale)", log_scale = FALSE)
outdeg_hist0505 <- plot_hist(outdeg_0505, "out-degree distribution for 0505", "out-degree", "frequency (log scale)", log_scale = FALSE)
outdeg_hist0601 <- plot_hist(outdeg_0601, "out-degree distribution for 0601", "out-degree", "frequency (log scale)", log_scale = FALSE)

grid.arrange(outdeg_hist0302, outdeg_hist0312, outdeg_hist0505, outdeg_hist0601, ncol = 2)
```


```{r sampling}
in_deg <- in_deg %>% mutate(bin = cut(deg, breaks = 100, labels = FALSE))

sampled_df <- in_deg %>%
  group_by(bin) %>%
  sample_frac(0.0001, replace = FALSE) %>%
  ungroup()

#get subgraph from sampled vertices
subg <- induced_subgraph(g1, row.names(sampled_df))

#get largest component
comps <- clusters(subg)
largest_comp_ind <- which.max(comps$csize)
largest_comp_vert <- which(comps$membership == largest_comp_ind)

plot(induced_subgraph(g1, largest_comp_vert), layout = layout.fruchterman.reingold(subg))
```



