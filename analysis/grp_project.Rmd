---
title: "Group Project (exploration)"
author: "group"
date: "2023-09-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(dplyr)
library(tidyr)
library(igraph)
library(data.table)
library(glue)
library(gridExtra)
library(ggplot2)
library(stringr)
library(here)
```

```{r , setup, include=FALSE}
#set working directory to project root folder
knitr::opts_knit$set(root.dir = here())
```

**Project Background**

Established in 1995 as a pioneering online bookstore, Amazon has been a cherished destination for book enthusiasts for several decades. While the company has evolved and expanded into a diverse range of industries, it has consistently maintained its status as a go-to hub for book shoppers.

In the scope of this project, our objective is to delve into the evolving co-purchase patterns of books over time, understand it's characteristics and underlying patterns. With these information, we'll then develop a model that can provide personalized book recommendations based on books which the customer has added to his/her basket.

In doing so, we anticipate that our efforts will yield a mutually beneficial outcome. By facilitating book discoveries and guiding readers to titles they might not have encountered otherwise, we aim to stimulate sales on the platform, benefiting both Amazon and its thriving community of book lovers.

**1. Network Characteristics**

Note:

On our end, the metadata is collected in summer 2006 (possible dates is Wed, 21 Jun 2006 â€“ Sat, 23 Sept 2006), and our co-purchase data: `amazon0312` was collected in March 02 2003.

The number of months from the midpoint of summer, 7 August 2006, to March 02 2003 is 30 months 3 weeks, thus we round up to 31 months.

we've filtered for such book-to-book co-purchases:
1. With average reviews > 1 in 31 month period (for both books)
2. in a co-purchase, both books have a valid genre i.e., not an empty string

```{r read_data}
set.seed(123)

# Read the graph from the GraphML file
g <- read_graph(here("outputs/filtered_graph.graphml"), format = "graphml")
# read filtered book data
books_df <- read.csv(here("outputs/book_filtered.csv"))
# changing id column and vertex ids from 'int' to 'chr' dtype
books_df$id <- as.character(books_df$id)

g

head(books_df)
```

```{r combinations}
#generate combinations
sample_nodes <- V(g) %>% as_ids()
combinations <- combn(sample_nodes, 2, simplify = TRUE)

combi <- combinations[,1]
combi

#function to check if a given pair of nodes are connected in a given graph
check_connection <- function(combi) {
  result <- are.connected(g, combi[1], combi[2])
  return(result)
}

#check if each pair of nodes are connected
is_connected <- combinations %>% apply(., 2, check_connection)

df_edgelist = data.frame(V1 = combinations[1,], V2 = combinations[2,], is_connected = is_connected)
```

```{r combining_edgelist_with_data}
df_edgelist_book <- df_edgelist %>% left_join(books_df %>% select(id, length, rating, reviews, salesrank) %>% rename(V1_length = length, V1_rating = rating, V1_reviews = reviews, V1_salesrank = salesrank), by  = c("V1" = "id")) %>% left_join(books_df %>% select(id, length, rating, reviews, salesrank) %>% rename(V2_length = length, V2_rating = rating, V2_reviews = reviews, V2_salesrank = salesrank), by  = c("V2" = "id"))

df_edgelist_book
```

```{r aggreating_number_common_genres}

# First, split the genres for each unique node
node_genres <- books_df %>%
  select(id, cleaned_genres) %>%
  distinct() %>%
  mutate(genres_list = strsplit(cleaned_genres, "\\|"))

# Create a named list for fast lookup
genre_list <- setNames(node_genres$genres_list, node_genres$id)

# Compute the number of common genres for each row in edgelist
df_edgelist_book$num_common_genre <- mapply(function(v1, v2) {
  length(intersect(genre_list[[as.character(v1)]], genre_list[[as.character(v2)]]))
}, df_edgelist_book$V1, df_edgelist_book$V2)

# converting dependent variable, is_connected to binary variable
df_edgelist_book$is_connected <- df_edgelist_book$is_connected * 1

#save csv
write.csv(df_edgelist_book, "baseline_dataset.csv", row.names = FALSE)
```


```{r analysing_baseline_dataset}
class_proportions <- df_edgelist_book %>% group_by(is_connected) %>% tally()
print(class_proportions)
# The dataset is highly imbalanced and this needs to be handled as if it is not dealt with properly, the algorithm will not be able to learn the characteristics of the minority class properly. Therefore, up-sampling or down-sampling techniques can be used to ensure equal or more balanced proportions between the two classes.
```

```{r creating_baseline_model}



```


```{r node_attributes}

# store attributes into a data.frame
node_attributes_df=data.frame(vertex_id=V(g)$name, 
                              degree = degree(g),
                              closeness=closeness(g, mode='all'),
                              betweenness=betweenness(g, directed=FALSE),
                              transitivity=transitivity(g, type = "local"), # There are many NaN transitivity values; it means these nodes are isolated?
                              eigen_centrality = eigen_centrality(g)$vector,
                              page_rank = page_rank(g)$vector,
                              component_membership = components(g)$membership) #should we specify weakly or strongly connected component?


head(node_attributes_df)
```

```{r merging_node_attributes_books_df}
merged_df = books_df %>% left_join(node_attributes_df, by = c("id" = "vertex_id"))
head(merged_df)
```

**2.1. Degree Centrality**

The degree distribution of our network exhibits a power-law distribution, a characteristic often seen in naturally occurring networks. Majority of books in our network have low degree centrality, typically three or fewer connections. On the far right of the distribution, we observe a small group of books with 12 or more first-degree connections, indicating a significant influence on the purchase of other books.

This suggests that most books within the network neither strongly influence the purchase of other books nor are significantly influenced by other books. Examining these high in-degree centrality outliers can provide valuable insights, which could allow us to formulate effective cross-selling strategies that enhance co-purchase tendencies.

```{r deg_visualization, fig.width=15, fig.height=5}
#function to plot histogram
plot_hist <- function(g, title, x_label, y_label, log_scale = FALSE) {
  labels <- labs(y = y_label, x = x_label, title = title)  # Added title parameter
  graph <- ggplot() + geom_histogram(aes(x = g), bins = 10) + labels
  
  if (log_scale == TRUE) {
    return(graph + ls)
  } else {
    return(graph)
  }
}

#calculate in, out and all degree centrality for each graph
deg <- degree(g)

#visualize
plot_hist(deg, "degree distribution for 0302", "degree", "frequency")
```

**2.2. Degree Centrality**
The low network density of 0.000598 in the network indicates that, relative to the total possible connections between books, there are very few actual co-purchases. This suggests that the network is quite sparse, with a limited number of co-purchases taking place.

Global transitivity measures how likely the neighbors of two connected nodes are connected to each other. In the case of our co-purchase network, it measures the likelihood that the alters of two books which are co-purchased together are also co-purchased with each other. The moderate global transitivity value of 0.242 tells us that there is a noteworthy degree of clustering or transitivity within this sparse network. 

This means that, despite the overall sparsity, there is a tendency for co-purchased books to have shared co-purchases with other books in the network. In simpler terms, when two books are co-purchased together, there is a relatively higher likelihood that other books co-purchased with those two are also co-purchased with each other. 

This suggests that there are distinct co-purchase patterns or niche markets within the network. Products within these clusters frequently co-purchase with each other, even if the overall network is not densely interconnected.

```{r graph-attributes}
global_transitivity = transitivity(g, type="global")
density = graph.density(g)
print(paste("The global transitivity of the graph is", global_transitivity, "and the graph density is", density))
```

# Clusters

```{r component, fig.width = 15, fig.height = 10}
#get largest component
comps <- clusters(g)
largest_comp_ind <- which.max(comps$csize)
largest_comp_vert <- which(comps$membership == largest_comp_ind)
largest_comp_subg <- induced_subgraph(g, largest_comp_vert)

#visualize largest component
plot(largest_comp_subg, layout = layout.fruchterman.reingold(g), vertex.size = degree(largest_comp_subg))
#degree distribution for sampled graph
plot_hist(degree(g), "Degree Centrality distribution for sampled graph", "degree centrality", "frequency", log_scale = FALSE)
#degree distribution for largest component
plot_hist(degree(largest_comp_subg), "Degree Centrality distribution for largest component", "degree centrality", "frequency", log_scale = FALSE)
```


# Clustering

Source Codes

https://cran.r-project.org/web/packages/linkprediction/linkprediction.pdf

https://rpubs.com/writetosamadalvi/CommunityDetection

https://users.dimi.uniud.it/~massimo.franceschet/R/communities.html

https://rstudio-pubs-static.s3.amazonaws.com/734940_93adb495f0e34ca291fcda1d214129d1.html#Service_as_a_Freelancer









